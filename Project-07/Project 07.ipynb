{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operator seluler Megaline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daftar Isi <a id='back'></a>\n",
    "\n",
    "* [Pendahuluan](#intro)\n",
    "\n",
    "* [Tahap 1. Ikhtisar Data](#data_review)\n",
    "  \n",
    "* [Tahap 2. Analisis](#analysis)\n",
    "    * [2.1 Membagi set train, set valid, dan set test](#als_train_valid_test)\n",
    "    * [2.2 Pengujian Model](#als_uji_model)\n",
    "    * [2.2.1 Decision Tree](#als_uji_dec_tree)\n",
    "    * [2.2.2 Random Forest](#als_uji_rand_for)\n",
    "    * [2.2.3 Logistic Regression](#als_uji_log_regr)\n",
    "    * [2.3 Quality Check menggunakan set test](#als_quality_check)\n",
    "    * [2.4 Sanity Check: Model dibandingkan dengan Peluang](#als_sanity_check)\n",
    "\n",
    "* [Temuan](#end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pendahuluan <a id='intro'></a>\n",
    "\n",
    "Operator seluler Megaline merasa tidak puas karena banyak user mereka yang masih menggunakan paket lama. Perusahaan tersebut ingin mengembangkan sebuah model yang dapat menganalisis perilaku konsumen dan merekomendasikan salah satu dari kedua paket terbaru Megaline: Surf atau Ultimate.\n",
    "\n",
    "Peneliti memiliki akses terhadap data perilaku para user yang sudah beralih ke paket terbaru (dari proyek kursus Analisis Data Statistik). Dalam tugas klasifikasi ini, Peneliti perlu mengembangkan sebuah model yang mampu memilih paket dengan tepat.\n",
    "\n",
    "\n",
    "### Tujuan: \n",
    "Peneliti akan mengembangkan model yang memilih paket yang tepat untuk user berdasarkan data perilaku pelanggan yang telah beralih ke paket baru, Smart atau Ultra. Peneliti mencari model yang setidaknya 75% akurat. Mengingat hal ini adalah tugas klasifikasi, kita akan menguji classifier Decision Tree, classifier Random Forest, dan classifier Logistic Regression.\n",
    "\n",
    "Melakukan pengujian klasifikasi dengan model:\n",
    "* Decision Tree\n",
    "* Random Forest\n",
    "* Logistic Regression\n",
    "\n",
    "\n",
    "### Tahapan\n",
    "Data perilaku user dari operator seluler Megaline yang disimpan dalam *file*:\n",
    "- /datasets/users_behavior.csv\n",
    "\n",
    "Mengingat Peneliti telah menyelesaikan langkah pra-pemrosesan data, Peneliti bisa langsung menuju ke tahap pembuatan model. Data tersebut dapat langsung diuji pada model klasifikasi yang akan digunakan dengan membaginya menjadi set data:\n",
    "* set train\n",
    "* set valid\n",
    "* set test\n",
    "\n",
    "Proyek ini akan terdiri dari dua tahap:\n",
    " 1. Ikhtisar Data\n",
    " 2. Analisis\n",
    "\n",
    " \n",
    "[Kembali ke Daftar Isi](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tahap 1. Ikhtisar Data <a id='data_review'></a>\n",
    "\n",
    "Melakukan import library yang diperlukan, membuka data terkait yang akan dievaluasi, kemudian menjelajahi data tersebut."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1.1**\n",
    "Melakukan import libraries dan modules yang diperlukan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #untuk pengolahan dataframes\n",
    "from sklearn.tree import DecisionTreeClassifier #untuk pengolahan model Decision Tree\n",
    "from sklearn.ensemble import RandomForestClassifier #untuk pengolahan model Random Forest\n",
    "from sklearn.linear_model import LogisticRegression #untuk pengolahan  model Logistic Regression\n",
    "from sklearn.model_selection import train_test_split #untuk kebutuhan pembagian dataset\n",
    "from sklearn.metrics import accuracy_score #untuk menghitung accuracy dari model yang digunakan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1.2**\n",
    "Melakukan load data yang diperlukan dari file *users_behavior.csv*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    df = pd.read_csv('users_behavior.csv')\n",
    "except:\n",
    "    games = pd.read_csv('/datasets/users_behavior.csv')\n",
    "#membaca the csv file and konversi ke dataframe df\n",
    "\n",
    "df.head() #melihat 5 baris awal dari dataframe df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()#menampilkan informasi umum dataframe df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature yang ada adalah kolom calls, minutes, messages, dan mb_used, yang akan digunakan untuk predict target, yakni kolom is_ultra, berdasarkan model yang telah di-train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Kembali ke Daftar Isi](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tahap 2. Analisis <a name='analysis'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Membagi set train, set valid, dan set test <a name=\"als_train_valid_test\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2.1**\n",
    "Kita perlu membagi set train, set valid, dan set test. Untuk melakukan hal ini, kita menggunakan fungsi train_test_split(). Fungsi ini membagi kumpulan data menjadi 2. Karena kita memerlukan 3 kumpulan, kita perlu melakukannya dua kali. Persentase kumpulan data asli diset menjadi 60, 20, dan 20 untuk masing-masing set train, set valid, dan dan set test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df2 = train_test_split(df, test_size=0.4, random_state=12345)\n",
    "#membagi df menjadi df_train (60%) dan df2 (40%)\n",
    "df_valid, df_test = train_test_split(df2, test_size=0.5, random_state=12345)\n",
    "#membagi df2 menjadi df_valid(50% dari df2, yang berarti 20% dari df) dan df_test(50% dari df2, yang berarti 20% dari df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2.2**\n",
    "Melihat informasi umum dari setiap set split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1928 entries, 3027 to 482\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     1928 non-null   float64\n",
      " 1   minutes   1928 non-null   float64\n",
      " 2   messages  1928 non-null   float64\n",
      " 3   mb_used   1928 non-null   float64\n",
      " 4   is_ultra  1928 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 90.4 KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info() #informasi set training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 643 entries, 1386 to 3197\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     643 non-null    float64\n",
      " 1   minutes   643 non-null    float64\n",
      " 2   messages  643 non-null    float64\n",
      " 3   mb_used   643 non-null    float64\n",
      " 4   is_ultra  643 non-null    int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 30.1 KB\n"
     ]
    }
   ],
   "source": [
    "df_valid.info() #informasi set validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 643 entries, 160 to 2313\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     643 non-null    float64\n",
      " 1   minutes   643 non-null    float64\n",
      " 2   messages  643 non-null    float64\n",
      " 3   mb_used   643 non-null    float64\n",
      " 4   is_ultra  643 non-null    int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 30.1 KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info() #informasi set test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita telah membagi kumpulan data asli menjadi set training (60%), set validation (20%), dan set test (20%). Kita sekarang perlu menentukan feature dan target untuk setiap set. Untuk feature-nya, kita akan mengambil seluruh dataframe yang dihapus kolom target-nya, yakni kolom is_ultra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2.3**\n",
    "Membuat feature dan target untuk setiap set baik set training, set validation, maupun set test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = df_train.drop('is_ultra', axis=1)\n",
    "#membentuk feature train dengan menghapus kolom target dari set train\n",
    "\n",
    "train_target = df_train['is_ultra']\n",
    "#membentuk target train yang merupakan kolom is_ultra pada set train\n",
    "\n",
    "valid_features = df_valid.drop('is_ultra', axis=1)\n",
    "#membentuk feature valid dengan menghapus kolom target dari set valid\n",
    "\n",
    "valid_target = df_valid['is_ultra']\n",
    "#membentuk target valid yang merupakan kolom is_ultra pada set valid\n",
    "\n",
    "test_features = df_test.drop('is_ultra', axis=1)\n",
    "#membentuk feature test dengan menghapus kolom target dari set test\n",
    "\n",
    "test_target = df_test['is_ultra']\n",
    "#membentuk target test yang merupakan kolom is_ultra pada set test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita telah mendefinisikan feature dan target untuk setiap set sehingga dapat dilanjutkan dengan  pengujian model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pengujian Model <a name=\"als_uji_model\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita akan melakukan pengujian klasifikasi model Decision Tree, klasifikasi model Random Forest, dan model klasifikasi Logistic Regression dan melatihnya dengan set train (menggunakan metode fit()) dan mengujinya pada set valid dengan membandingkan prediksi menggunakan feature dari set valid (menggunakan metode predict()) ke target sebenarnya dari set valid. \n",
    "Kita akan menyesuaikan masing-masing hyperparameter untuk mendapatkan nilai accuracy yang lebih tinggi, yang terakhir menjadi metrik untuk memilih model terbaik yang digunakan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree <a name=\"als_uji_dec_tree\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita akan menggunakan fungsi DecisiontreeClassifier(). Hyperparameter yang digunakan adalah random_state dan max_depth. Hyperparameter random_state harus sama secara keseluruhan sehingga kita akan memberikannya nilai tetap (12345). Hyperparameter max_depth adalah hyperparameter yang akan kita gunakan lebih dalam. Kita akan mengulang sekumpulan nilai untuk max_depth (dalam hal ini 1 hingga 10) dan mendapatkan skor akurasinya untuk mencari mana yang terbaik."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2.4**\n",
    "Membuat for loop untuk melakukan pengujian model Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max depth 1 accuracy = 0.7542768273716952\n",
      "Max depth 2 accuracy = 0.7822706065318819\n",
      "Max depth 3 accuracy = 0.7853810264385692\n",
      "Max depth 4 accuracy = 0.7791601866251944\n",
      "Max depth 5 accuracy = 0.7791601866251944\n",
      "Max depth 6 accuracy = 0.7838258164852255\n",
      "Max depth 7 accuracy = 0.7822706065318819\n",
      "Max depth 8 accuracy = 0.7791601866251944\n",
      "Max depth 9 accuracy = 0.7822706065318819\n",
      "Max depth 10 accuracy = 0.7744945567651633\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 11): #loop melalui nilai i dari 1 hingga 10    \n",
    "    dt_model = DecisionTreeClassifier(random_state=12345, max_depth=i)\n",
    "    #membuat model Decision Tree dengan nilai max_depth berupa i\n",
    "    dt_model.fit(train_features, train_target)\n",
    "    #train model dengan menggunakan feature dan target dari set train\n",
    "    dt_valid_pred=dt_model.predict(valid_features)\n",
    "    #mendapatkan prediction dari model dengen menggunakan feature dan target dari set valid\n",
    "    print('Max depth', i, 'accuracy =', accuracy_score(valid_target, dt_valid_pred))\n",
    "    #mencetak nilai accuracy dengan membandingkan prediction terhadap target dari set valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Decision Tree terbaik adalah yang memiliki max_ depth 3 karena memiliki nilai akurasi tertinggi sebesar 79%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest <a name=\"als_uji_rand_for\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita menjalankan RandomForestClassifier(). Hyperparameter random_state kita harus tetap sama seperti sebelumnya. Hyperparameter yang akan kita mainkan adalah max_ depth dan n_estimators. Dalam hal ini pertama-tama kita akan membuat daftar kosong. Kemudian kita akan membuat loop nilai max_depth dan, di dalam loop tersebut dilakukan pengulangan penerapan nilai n_estimators. Kita akan menggunakan loop ini untuk membuat model dengan permutasi berbeda dari nilai max_ depth dan n_estimators yang akan kita simpan dalam daftar, di mana selanjutnya kita akan memilih model dengan nilai accuracy tertinggi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2.5**\n",
    "Membuat for loop untuk melakukan pengujian model Random Forest terbaik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=8, n_estimators=40, random_state=12345)\n"
     ]
    }
   ],
   "source": [
    "rf = []\n",
    "#membuat list kosong\n",
    "for i in range(1, 11):\n",
    "#loop melalui nilai i dari 1 hingga 10 untuk max_depth\n",
    "    for j in range(10, 101, 10):\n",
    "    #loop melalui nilai j dari 1 hingga 100 dengan step 10 untuk n_estimators\n",
    "        rf_model = RandomForestClassifier(random_state=12345, max_depth=i, n_estimators=j)\n",
    "        #membuat model random forest\n",
    "        rf_model.fit(train_features, train_target)\n",
    "        #trains model menggunakan feature dan target dari set train\n",
    "        rf.append(rf_model)\n",
    "        #menambahkan model ke dalam daftar\n",
    "    \n",
    "print(max(rf, key=lambda rf_model: accuracy_score(rf_model.predict(valid_features), valid_target)))\n",
    "#mencetak model dengan nilai accuracy tertinggi berdasarkan prediction yang dihitung dengan menggunakan feature dari set valid dan target aktual dari set valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasil menunjukkan bahwa model klasifikasi Random Forest terbaik adalah model dengan max_ depth=8 dan n_estimators=40. Kita sebut sebagai best_rf. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2.6**\n",
    "Menghitung nilai akurasi untuk model klasifikasi Random Forest terbaik dengan menggunakan best_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8087091757387247\n"
     ]
    }
   ],
   "source": [
    "best_rf=RandomForestClassifier(random_state=12345, max_depth=8, n_estimators=40)\n",
    "best_rf.fit(train_features, train_target)\n",
    "best_rf_pred=best_rf.predict(valid_features)\n",
    "print(accuracy_score(valid_target, best_rf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Klasifikasi Random Forest terbaik memiliki nilai accuracy sebesar 81%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression <a name=\"als_uji_log_regr\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita menggunakan fungsi LogisticRegression(). Hyperparameter random_state harus sama, namun hyperparameter max_ depth dan n_estimators tidak berlaku di sini. Yang kita perlukan hanyalah menetapkan hyperparameter solver. Untuk hal tersebut kita menggunakan 'liblinear'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2.7**\n",
    "Train model Logistic Regression dan menghitung nilai accuracy model tersebut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy = 0.7076205287713841\n"
     ]
    }
   ],
   "source": [
    "lr_model = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "lr_model.fit(train_features, train_target)\n",
    "lr_valid_pred=lr_model.predict(valid_features)\n",
    "print('Logistic Regression Accuracy =', accuracy_score(valid_target, lr_valid_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nilai accuracy model Logistic Regression model adalah 76%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model manakah yang terbaik?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model terbaik yang kami dihasilkan adalah model Random Forest dengan max_ depth = 8 dan n_estimators = 40 dengan nilai accuracy 81%. Di posisi kedua adalah model Decision Tree dengan max_ depth = 3 dengan nilai accuracy 79%. Dan di posisi terakhir adalah model Regresi Logistik dengan nilai accuracy 76%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality Check menggunakan set test <a name=\"als_quality_check\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita sekarang  menggunakan model terbaik pada set test. Sebelumnya, kita perlu melatih ulang model tersebut menggunakan gabungan set train dan set valid. Untuk menggabungkan set tersebut, kita dapat menggunakan fungsi pd.concat dengan menjadikan daftar set yang dipanggil sebagai argumen dan mengatur parameter axis=0 untuk menjadikannya sebagai tumpukan vertikal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2.8**\n",
    "Menggabungkan set train dan set valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2571 entries, 3027 to 3197\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     2571 non-null   float64\n",
      " 1   minutes   2571 non-null   float64\n",
      " 2   messages  2571 non-null   float64\n",
      " 3   mb_used   2571 non-null   float64\n",
      " 4   is_ultra  2571 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 120.5 KB\n"
     ]
    }
   ],
   "source": [
    "train_final = pd.concat([df_train, df_valid], axis=0)\n",
    "#menumpuk secara vertikal set train dan set valid\n",
    "train_final.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2.9**\n",
    "Menetapkan feature dan target untuk set gabungan tersebut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final_features = train_final.drop('is_ultra', axis=1)\n",
    "train_final_target = train_final['is_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sekarang kita dapat melatih (metode fit()) menggunakan feature dan target yang baru (gabungan train dan valid), yang dilanjutkan dengan membuat prediction (metode predict()) menggunakan feature dari set test, dan mendapatkan nilai akurasi. Model terbaik tetap disebut sebagai 'best_rf'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2.10**\n",
    "Melatih model, menggunakan feature dan target gabungan, membuat prediction, dan menghitung nilai akurasi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7993779160186625\n"
     ]
    }
   ],
   "source": [
    "best_rf.fit(train_final_features, train_final_target)\n",
    "best_rf_pred=best_rf.predict(test_features)\n",
    "print(accuracy_score(best_rf_pred, test_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nilai accuracy yang didapatkan adalah 80% melebihi ambang batas (threshold) 75%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Check: Model dibandingkan dengan Peluang <a name=\"als_sanity_check\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untuk melakukan Sanity Check terhadap model kita, perlu dilakukan perbandingan dengan peluang. Kita dapat melakukannya dengan mendapatkan nilai akurasi jika prediction kita mengasumsikan bahwa kita memberikan satu nilai untuk seluruh target. Untuk hal tersebut, kita lihat berapa banyak user Smart dan Ultra yang kita miliki pada set test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2.11**\n",
    "Melihat data jumlah pengguna masing-masing paket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah pengguna paket Smart: 440\n",
      "Jumlah pengguna paket Ultra: 203\n"
     ]
    }
   ],
   "source": [
    "smart_target=(test_target == 0) #nilai True untuk pengguna paket Smart\n",
    "ultra_target=(test_target == 1) #nilai True untuk pengguna paket Ultra\n",
    "\n",
    "print('Jumlah pengguna paket Smart:', smart_target.sum())\n",
    "print('Jumlah pengguna paket Ultra:', ultra_target.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita memiliki lebih banyak user paket Smart, untuk selanjutnya kita akan menggunakan mereka sebagai contoh, yakni dengan mengasumsikan kita memiliki random classifier dengan prediction hanya 0 (yaitu paket Smart) selama set test. Kemudian dicari nilai accuracy-nya."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2.12**\n",
    "Menghitung peluang paket Smart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nilai accuracy dari random classifier: 0.6842923794712286\n"
     ]
    }
   ],
   "source": [
    "peluang_smart=smart_target.sum()/len(test_target)\n",
    "print('Nilai accuracy dari random classifier:', peluang_smart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random classifier memiliki skor akurasi 68,4%, kurang dari 80% yang diperoleh classifier Random Forest sebelumnya. Jadi model kita lolos Sanity Check."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Kembali ke Daftar Isi](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temuan <a name=\"end\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita telah membagi data menjadi set train, set valid, dan set test. Kita telah menguji model dan menemukan bahwa RandomForestClassifier adalah yang terbaik, mendapatkan nilai accuracy 81% pada set valid dan 79% pada set test dan lulus pemeriksaan sanity check."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Kembali ke Daftar Isi](#back)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

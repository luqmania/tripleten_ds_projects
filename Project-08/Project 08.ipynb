{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beta Bank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daftar Isi <a id='back'></a>\n",
    "\n",
    "* [Pendahuluan](#intro)\n",
    "\n",
    "* [Tahap 1. Ikhtisar Data](#data_review)\n",
    "    * [1.1 Kesimpulan](#review_conclusion)\n",
    "\n",
    "* [Tahap 2. Pra-pemrosesan data](#data_preprocessing)\n",
    "    * [2.1 Menghapus beberapa kolom yang kurang relevan terhadap penelitian](#dataprep_1)\n",
    "    * [2.2 Menangani kolom yang memiliki missing value](#dataprep_2)\n",
    "    * [2.3 Menerapkan dummies untuk kolom kategorikal](#dataprep_3)\n",
    "    * [2.4 Menerapkan skala untuk kolom numerikal](#dataprep_4)\n",
    "    * [2.5 Kesimpulan](#dataprep_conclusion)    \n",
    "    \n",
    "* [Tahap 3. Analisis](#analysis)\n",
    "    * [3.1 Membentuk feature dan target dengan split data](#analysis_1)\n",
    "    * [3.1.1 Set train, set valid, dan set test](#analysis_1_1)\n",
    "    * [3.2 Membentuk feature dan target dengan split data](#analysis_2)\n",
    "    * [3.2.1 Klasifikasi Decision Tree](#analysis_2_1)\n",
    "    * [3.2.2 Klasifikasi Random Forest](#analysis_2_2)\n",
    "    * [3.2.3 Logistic Regression](#analysis_2_3)\n",
    "    * [3.3 Memperhitungkan Class Imbalance](#analysis_3)\n",
    "    * [3.3.1 Penyesuaian Class Weight](#analysis_3_1)\n",
    "    * [3.3.2 Upsampling](#analysis_3_2)\n",
    "    * [3.4 Kesimpulan](#analysis_conclusion)\n",
    "\n",
    "\n",
    "* [Tahap 4. Pengujian](#test)\n",
    "    * [4.1 Pengujian pada set test\"](#test_1)\n",
    "\n",
    "* [Temuan](#end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Kembali ke Daftar Isi](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pendahuluan <a id='intro'></a>\n",
    "\n",
    "Nasabah Bank Beta pergi meninggalkan perusahaan: sedikit demi sedikit, jumlah mereka berkurang setiap bulannya. Para pegawai bank menyadari bahwa akan lebih menghemat biaya jika perusahaan fokus untuk mempertahankan nasabah lama mereka yang setia daripada menarik nasabah baru. \n",
    "\n",
    "Peneliti membantu Bank Beta untuk memprediksi apakah nasabah akan leave atau stay berdasarkan Credit Score, Geographical Location, Gender,\tAge, Tenure (berapa lama mereka telah berada di bank), Balance,\tNumber of Products yang mereka gunakan, apakah mereka memiliki kartu kredit, apakah mereka nasabah aktif, dan Estimated Salary. Informasi ini telah dikumpulkan dalam kumpulan data yang akan peneliti pelajari selanjutnya.\n",
    "\n",
    "### Tujuan: \n",
    "Pada kasus ini, tugas peneliti adalah untuk memprediksi apakah seorang nasabah akan segera meninggalkan bank atau tidak. \n",
    "\n",
    "Membuat model dengan:\n",
    "* Decision Tree\n",
    "* Random Forest\n",
    "* Logistic Regression\n",
    "\n",
    "Menangani class imbalance dengan:\n",
    "* Penyesuaian Class Weight\n",
    "* Upsampling\n",
    "\n",
    "### Tahapan\n",
    "Peneliti memiliki data terkait  para klien yang disimpan dalam *file*:\n",
    "- /datasets/Churn.csv\n",
    "\n",
    "Tidak ada informasi terkait kualitas data tersebut, jadi perlu diperiksa terlebih dahulu sebelum melakukan analisis lebih lanjut.\n",
    "\n",
    "Pertama akan dilakukan evaluasi kualitas data dan melihat apakah terdapat hal yang signifikan yang perlu dilakukan tindak lanjut sebelum dilakukan proses analisis.\n",
    "\n",
    "Proyek ini akan terdiri dari empat tahap:\n",
    " 1. Ikhtisar Data\n",
    " 2. Pra-pemrosesan Data \n",
    " 3. Analisis\n",
    " 4. Pengujian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Kembali ke Daftar Isi](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Tahap 1. Ikhtisar Data <a id='data_review'></a>\n",
    "\n",
    "Melakukan import library yang diperlukan, membuka data terkait yang akan dievaluasi, kemudian menjelajahi data tersebut."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1.1**\n",
    "Melakukan import libraries dan modules yang diperlukan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #untuk mengelola dataframe\n",
    "from sklearn.tree import DecisionTreeClassifier #untuk mengolah model Decision Tree\n",
    "from sklearn.ensemble import RandomForestClassifier #untuk mengolah model Random Forest\n",
    "from sklearn.linear_model import LogisticRegression #untuk mengolah model Logistic Regression\n",
    "from sklearn.model_selection import train_test_split #untuk melakukan split dataset\n",
    "from sklearn.preprocessing import StandardScaler #untuk melakukan penskalaan nilai\n",
    "from sklearn.utils import shuffle #untuk melakukan pengacakan kolom\n",
    "from sklearn.metrics import f1_score #untuk menghitung nilai f1 dari model\n",
    "from sklearn.metrics import roc_auc_score #untuk menghitung nilai auc-roc dari model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1.2**\n",
    "Melakukan load data yang diperlukan dari file *churn.csv* dan menyimpan ke\n",
    "dalam dataframe df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    df = pd.read_csv('Churn.csv')\n",
    "except:\n",
    "    df = pd.read_csv('/datasets/Churn.csv')\n",
    "#membaca file csv dan konversi ke dataframe df\n",
    "\n",
    "df.head() \n",
    "#melihat 5 baris awal dari dataframe df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info() #melihat informasi umum tentang dataframe df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kolom Exited akan menjadi target sedangkan kolom lainnya akan berfungsi sebagai feature. Kita perlu membuat dummies untuk kolom kategorikal. Kemudian, kita perlu menskalakan kolom numerikal, kecuali kolom dengan nilai biner (0 atau 1) seperti kolom HasCrCard dan kolom IsActiveMember."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RowNumber            0\n",
       "CustomerId           0\n",
       "Surname              0\n",
       "CreditScore          0\n",
       "Geography            0\n",
       "Gender               0\n",
       "Age                  0\n",
       "Tenure             909\n",
       "Balance              0\n",
       "NumOfProducts        0\n",
       "HasCrCard            0\n",
       "IsActiveMember       0\n",
       "EstimatedSalary      0\n",
       "Exited               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum() #memeriksa missing value pada dataframe df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terdapat missing value pada kolom Tenure, mengingat kolom Tenure bersifat numerikal kita dapat mengisi nilai yang hilang pada kolom Tenure dengan nilai median agar tidak bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum() #memeriksa nilai yang terduplikasi pada dataframe df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tidak terdapat nilai yang terduplikasi dalam dataframe df. Oleh karenanya tidak perlu dilakukan tindakan lebih lanjut terkait duplicated value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Kembali ke Daftar Isi](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kesimpulan <a name=\"review_conclusion\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data type kolom pada dataframe df telah sesuai dan dapat diproses untuk analisis lebih lanjut. Untuk analisis lebih lanjut, terdapat kolom yang kurang relevan yang dapat didrop yakni RowNumber, CustomerId, dan Surname. Terdapat missing value pada kolom Tenure sebanyak 909 item (9,09%) yang perlu ditindaklanjuti sebelum dilakukan analisis lebih lanjut. Tidak ada nilai yang terduplikasi sehingga tidak perlu dilakukan tindak lanjut terhadap duplicated value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tahap 2. Pra-pemrosesan Data <a id='data_preprocessing'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Menghapus beberapa kolom yang kurang relevan terhadap penelitian <a name=\"dataprep_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kolom yang kurang relevan tersebut adalah RowNumber, CustomerId, dan Surname. RowNumber pada dasarnya adalah indeks, hanya saja dimulai dari 1 dan bukan 0. CustomerId hanya untuk membedakan pelanggan secara unik, Nama Belakang juga merupakan alat identifikasi lainnya, keduanya berbeda untuk setiap pengamatan. Kolom-kolom ini tidak akan membantu dalam pelatihan model sehingga kita dapat menghapus kolom-kolom ini."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2.1**\n",
    "Menghapus kolom-kolom yang kurang relevan terhadap penelitian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   CreditScore      10000 non-null  int64  \n",
      " 1   Geography        10000 non-null  object \n",
      " 2   Gender           10000 non-null  object \n",
      " 3   Age              10000 non-null  int64  \n",
      " 4   Tenure           9091 non-null   float64\n",
      " 5   Balance          10000 non-null  float64\n",
      " 6   NumOfProducts    10000 non-null  int64  \n",
      " 7   HasCrCard        10000 non-null  int64  \n",
      " 8   IsActiveMember   10000 non-null  int64  \n",
      " 9   EstimatedSalary  10000 non-null  float64\n",
      " 10  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(6), object(2)\n",
      "memory usage: 859.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data=df.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
    "#menghapus kolom dari dataframe df and menamakan hasilnya menjadi data\n",
    "data.info()\n",
    "#melihat informasi umum tentang data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita telah berhasil menghapus beberapa kolom yang kurang relevan dengan penelitian."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Menangani kolom yang memiliki missing value <a name=\"dataprep_2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saat kita memeriksa nilai unik kolom Tenure, ditemukan nilai NaN (hilang)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2.2**\n",
    "Memeriksa isi kolom yang hilang (missing value) dan mengisinya dengan nilai yang tepat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.,  1.,  8.,  7.,  4.,  6.,  3., 10.,  5.,  9.,  0., nan])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Tenure'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita dapat mengisi sel kosong ini dengan nilai median agar tidak menimbulkan bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.,  1.,  8.,  7.,  4.,  6.,  3., 10.,  5.,  9.,  0.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Tenure']=data['Tenure'].fillna(data['Tenure'].median())#mengisi missing value dengan nilai median\n",
    "data['Tenure'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita telah berhasil menangani missing value pada kolom Tenure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Menerapkan dummies untuk kolom kategorikal <a name=\"dataprep_3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita memiliki 2 kolom yang bersifat kategorikal yakni Geography dan Gender."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2.3**\n",
    "Memeriksa kolom-kolom kategorikal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Geography\n",
       "France     5014\n",
       "Germany    2509\n",
       "Spain      2477\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Geography'].value_counts() #melihat rincian unique value yang dimiliki kolom Geography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender\n",
       "Male      5457\n",
       "Female    4543\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Gender'].value_counts() #melihat rincian unique value yang dimiliki kolom Gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada kolom Geografi terdapat 3 nilai yaitu Spain, Germany, dan France. Saat kita membuat dummies untuk kolom-kolom ini, kolom-kolom tersebut akan diganti dengan 3 kolom berikut yakni Geography_Spain, Geography_Germany, dan Geography_France. Setiap kolom akan mengambil nilai 1 pada observasi dimana kolom Geografi memiliki nilai country, selain itu akan mendapat 0. Hal yang sama akan terjadi pada kolom Gender. Kita akan menggunakan fungsi pd.get_dummies di seluruh tabel 'data' untuk kolom kategorikal. Kita dapat menghapus salah satu kolom dummies untuk kedua skenario tersebut karena terdapat angka 0 di Spain dan Germany, dengan kata lain berarti angka 1 untuk France. Kita dapat melakukan ini dengan menggunakah parameter drop_first=True."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2.4**\n",
    "Mengganti nilai kolom-kolom kategorikal dengan dummies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619   42     2.0       0.00              1          1   \n",
       "1          608   41     1.0   83807.86              1          0   \n",
       "2          502   42     8.0  159660.80              3          1   \n",
       "3          699   39     1.0       0.00              2          0   \n",
       "4          850   43     2.0  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  Geography_Germany  \\\n",
       "0               1        101348.88       1              False   \n",
       "1               1        112542.58       0              False   \n",
       "2               0        113931.57       1              False   \n",
       "3               0         93826.63       0              False   \n",
       "4               1         79084.10       0              False   \n",
       "\n",
       "   Geography_Spain  Gender_Male  \n",
       "0            False        False  \n",
       "1             True        False  \n",
       "2            False        False  \n",
       "3            False        False  \n",
       "4             True        False  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.get_dummies(data, drop_first=True)\n",
    "#mengganti kolom kategorikal dengan dummies dan menghapus dummies pertama untuk setiap kolom pengganti\n",
    "data.head()\n",
    "#meihat 5 baris awal dari dataframe data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita telah berhasil membuat dummies untuk kolom Geography dan Gender."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Menerapkan skala untuk kolom numerikal <a name=\"dataprep_4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kolom-kolom numerikal yakni 'CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', dan 'EstimatedSalary'. Variabel dalam kolom-kolom ini ini tidak memiliki rentang yang pasti sehingga kita perlu menskalakannya (atau menstandarkannya) dengan menggunakan z-score. Kita melakukan hal ini karena secara algoritma umum, variabel dengan penyebaran yang luas biasanya dianggap lebih penting dan kita tidak menginginkan hal tersebut terjadi. Jadi kita akan menjalankan fungsi StandardScaler(), kita akan fit() kolom numerikal di dalamnya dan melakukan transform untuk mendapatkan nilai berskala."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2.5**\n",
    "Melakukan proses penskalaan untuk nilai pada kolom-kolom numerikal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.326221</td>\n",
       "      <td>0.293517</td>\n",
       "      <td>-1.086246</td>\n",
       "      <td>-1.225848</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.021886</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.440036</td>\n",
       "      <td>0.198164</td>\n",
       "      <td>-1.448581</td>\n",
       "      <td>0.117350</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.216534</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.536794</td>\n",
       "      <td>0.293517</td>\n",
       "      <td>1.087768</td>\n",
       "      <td>1.333053</td>\n",
       "      <td>2.527057</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.240687</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.501521</td>\n",
       "      <td>0.007457</td>\n",
       "      <td>-1.448581</td>\n",
       "      <td>-1.225848</td>\n",
       "      <td>0.807737</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.108918</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.063884</td>\n",
       "      <td>0.388871</td>\n",
       "      <td>-1.086246</td>\n",
       "      <td>0.785728</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.365276</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore       Age    Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
       "0    -0.326221  0.293517 -1.086246 -1.225848      -0.911583          1   \n",
       "1    -0.440036  0.198164 -1.448581  0.117350      -0.911583          0   \n",
       "2    -1.536794  0.293517  1.087768  1.333053       2.527057          1   \n",
       "3     0.501521  0.007457 -1.448581 -1.225848       0.807737          0   \n",
       "4     2.063884  0.388871 -1.086246  0.785728      -0.911583          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  Geography_Germany  \\\n",
       "0               1         0.021886       1              False   \n",
       "1               1         0.216534       0              False   \n",
       "2               0         0.240687       1              False   \n",
       "3               0        -0.108918       0              False   \n",
       "4               1        -0.365276       0              False   \n",
       "\n",
       "   Geography_Spain  Gender_Male  \n",
       "0            False        False  \n",
       "1             True        False  \n",
       "2            False        False  \n",
       "3            False        False  \n",
       "4             True        False  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
    "#membuat list yang berisi kolom-kolom numerikal\n",
    "scaler = StandardScaler()\n",
    "#menjalankan fungsi scaler\n",
    "scaler.fit(data[numeric])\n",
    "#melakukan train scaler dengan data pada kolom-kolom numerikal\n",
    "data[numeric] = scaler.transform(data[numeric])\n",
    "#mentransform the data menjadi nilai berskala\n",
    "data.head()\n",
    "#meihat 5 baris awal dari dataframe data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita telah berhasil menskalakan nilai pada kolom-kolom numerikal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Kembali ke Daftar Isi](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kesimpulan <a name=\"dataprep_conclusion\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Telah dilakukan drop kolom yang kurang relevan yakni RowNumber, CustomerId, dan Surname. Telah dilakukan penggantian missing value pada kolom Tenure sebanyak 909 item dengan nilai median.\n",
    "Telah diterapkan dummies untuk kolom-kolom kategorikal (Geography dan Gender).  Telah diterapkan skala untuk kolom-kolom numerikal (CreditScore, Age, Tenure, Balance, NumOfProducts, dan EstimatedSalary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tahap 3. Analisis <a name='analysis'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Membentuk feature dan target dengan split data <a name=\"analysis_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kolom Exited adalah target sedangkan kolom lainnya adalah feature. Kita perlu membagi kedua set tersebut menjadi set train, set valid, dan set test yang masing-masing menghasilkan 60%, 20%, dan 20%. Untuk mendapatkannya, kita akan menjalankan fungsi train_test_split() dua kali. Pertama, kita akan membagi menjadi set train dan set kedua yang mengikuti atturan parameter test_size=0.4 (yang merupakan persentase dari set data yang seharusnya menjadi set kedua). Kemudian, kita akan melakukan split pada set kedua dari proses split sebelumnya menjadi dua ukuran yang sama (test_size=0.5) dan hasilnya adalah set valid (20% dari dataset asli) dan set test (20% dari dataset asli). Random_state akan diset menjadi 12345 dan akan tetap sama selama proses train model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set train, set valid, dan set test <a name=\"analysis_1_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3.1**\n",
    "Melakukan proses split untuk mendapatkan set train, set valid, dan set test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000 6000 2000 2000 2000 2000\n"
     ]
    }
   ],
   "source": [
    "features=data.drop('Exited', axis=1)\n",
    "#feature diset berisikan seluruh kolom kecuali kolom Exited\n",
    "target=data['Exited']\n",
    "#target diset sama dengan kolom Exited\n",
    "features_train, features_test_valid, target_train, target_test_valid=train_test_split(features, target,\\\n",
    "                                                                                      test_size=0.4,\\\n",
    "                                                                                     random_state=12345)\n",
    "#split pertama untuk mendapatkan set train untuk feature dan target (60%) dan set kedua (40%)\n",
    "features_valid, features_test, target_valid, target_test=train_test_split(features_test_valid, \\\n",
    "                                                                        target_test_valid, test_size=0.5, \\\n",
    "                                                                       random_state=12345)\n",
    "#split kedua pada set kedua dari proses split sebelumnya, yang membagi set validation dan set test sama besar\n",
    "print(len(features_train), len(target_train), len(features_valid), len(target_valid), len(features_test), \\\n",
    "     len(target_test))\n",
    "#mencetak data jumlah item dari 3 set feature dan target yang telah didapat dari proses split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita telah berhasil menetapkan feature dan target, serta membagi data menjadi set train, set valid, dan set test dengan proporsi telah ditentukan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Membangun Model dengan Class Imbalance <a name=\"analysis_2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Klasifikasi Decision Tree <a name=\"analysis_2_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita akan menjalankan fungsi DecisiontreeClassifier(). Kita akan melakukan setting 2 hyperparameter yakni random_state dan max_depth. Hyperparameter random_state harus konsisten secara keseluruhan sehingga kita akan memberikannya nilai tetap (12345). Hyperparameter max_depth adalah hyperparameter yang akan kita tindaklanjuti. Jadi kita akan mengulang sekumpulan nilai untuk max_depth (1 hingga 10) dan mendapatkan nilai f1 dan nilai AUC-ROC di mana keduanya merupakan metrik untuk kualitas model. F1_score memproses target dari validasi dan prediksi. Fungsi roc_auc_score memproses target dari validasi dengan probabilitas kelas positif dari setiap observasi dalam set valid. Kita menggunakan fungsi predct_proba() untuk keperluan ini."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2.7**\n",
    "Menentukan model klasifikasi Decision Tree dengan nilai F1 tertinggi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max depth 1 Nilai F1 = 0.0 Nilai AUC-ROC = 0.6925565119556736\n",
      "Max depth 2 Nilai F1 = 0.5217391304347825 Nilai AUC-ROC = 0.7501814673449512\n",
      "Max depth 3 Nilai F1 = 0.4234875444839857 Nilai AUC-ROC = 0.7973440741838507\n",
      "Max depth 4 Nilai F1 = 0.5528700906344411 Nilai AUC-ROC = 0.813428129858032\n",
      "Max depth 5 Nilai F1 = 0.5406249999999999 Nilai AUC-ROC = 0.8221680508592478\n",
      "Max depth 6 Nilai F1 = 0.5696969696969697 Nilai AUC-ROC = 0.8164631712023421\n",
      "Max depth 7 Nilai F1 = 0.5320813771517998 Nilai AUC-ROC = 0.8138530658907929\n",
      "Max depth 8 Nilai F1 = 0.5454545454545454 Nilai AUC-ROC = 0.8119854644656693\n",
      "Max depth 9 Nilai F1 = 0.5633802816901409 Nilai AUC-ROC = 0.7801515554775917\n",
      "Max depth 10 Nilai F1 = 0.5406162464985994 Nilai AUC-ROC = 0.7658451236699957\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 11): #loop melalui nilai i dari 1 hingga 10    \n",
    "    dt_model = DecisionTreeClassifier(random_state=12345, max_depth=i)\n",
    "    #membuat model Decision Tree dengan nilai max_depth berupa i\n",
    "    dt_model.fit(features_train, target_train)\n",
    "    #train model menggunakan feature dan target dari set train\n",
    "    dt_pred_valid=dt_model.predict(features_valid)\n",
    "    #mendapatkan prediction dari model menggunakan feature dari set valid\n",
    "    probabilities_valid = dt_model.predict_proba(features_valid)\n",
    "    #mendapatkan negative class probabilities dan positive class probabilities untuk setiap observasi feature dari set valid\n",
    "    probabilities_one_valid = probabilities_valid[:, 1]\n",
    "    #mendapatkan positive class probabilities untuk setiap observasi feature set valid\n",
    "    print('Max depth', i, 'Nilai F1 =', f1_score(target_valid, dt_pred_valid), 'Nilai AUC-ROC =', \\\n",
    "         roc_auc_score(target_valid, probabilities_one_valid))\n",
    "    #mencetak nilai f1 score dengan membandingkan predictions dengan target dari set valid sekaligus mencetak nilai auc_roc dengan membandingkan target set valid terhadap positive class probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nilai F1 terbaik 0.57 didapat dari percobaan model dengan max_depth 6, memiliki nilai AUC-ROC value 0.82"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Klasifikasi Random Forest <a name=\"analysis_2_2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita akan menjalankan fungsi RandomForestClassifier() di mana setting hyperparameter random_state kita harus tetap sama seperti sebelumnya. Hyperparameter yang akan kita gunakan adalah max_ depth dan n_estimators. Kita akan membuat daftar kosong, kemudian kita akan loop nilai max_depth dan juga loop nilai n_estimators di dalam loop tersebut. Kita akan menggunakan loop ini untuk mendapatkan model dengan permutasi berbeda dari nilai max_ depth dan n_estimators yang akan kita simpan dalam list, untuk selanjutnya dari sana kita akan memilih model dengan nilai f1 tertinggi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2.8**\n",
    "Menentukan model klasifikasi Random Forest dengan nilai F1 tertinggi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=10, n_estimators=10, random_state=12345)\n"
     ]
    }
   ],
   "source": [
    "rf = []#menyiapkapkan list kosong\n",
    "for i in range(1, 11):#loop melalui nilai i mulai 1 hingga 10 untuk max_depth\n",
    "    for j in range(10, 101, 10):#:#loop melalui nilai j mulai 1 hingga 100 dengan step 10 untuk n_estimator\n",
    "        rf_model = RandomForestClassifier(random_state=12345, max_depth=i, n_estimators=j)\n",
    "        #membuat model random forest\n",
    "        rf_model.fit(features_train, target_train)\n",
    "        #train model menggunakan feature dan target dari set train\n",
    "        rf.append(rf_model)#memasukkan model ke dalam list\n",
    "    \n",
    "print(max(rf, key=lambda rf_model: f1_score(rf_model.predict(features_valid), target_valid)))\n",
    "#mencetak model dengan nilai f1 tertinggi dari list berdasarkan prediction yang dibuat dengan menggunakan feature dari set valid dan target aktual dari set valid \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Random Forest dengan nilai F1 tertinggi memiliki setting hyperparameter max_ depth=10 dan n_estimators=10. Untuk selanjutnya kita dapat melatih dengan hyperparameter tersebut dan mendapatkan  nilai F1 dan ROC_AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 = 0.5869894099848714 AUC-ROC = 0.8461436676969979\n"
     ]
    }
   ],
   "source": [
    "best_rf_model = RandomForestClassifier(random_state=12345, max_depth=10, n_estimators=10)\n",
    "#membuat model\n",
    "best_rf_model.fit(features_train, target_train)\n",
    "#train model menggunakan feature dan target dari set train\n",
    "best_rf_pred = best_rf_model.predict(features_valid)\n",
    "#mendapatkan prediction dari model menggunakan feature dari set valid\n",
    "probabilities_rf_valid=best_rf_model.predict_proba(features_valid)\n",
    "#mendapatkan negative class probabilities dan positive class probabilities untuk setiap observasi feature dari set valid\n",
    "probabilities_rf_one_valid=probabilities_rf_valid[:, 1]\n",
    "#mendapatkan positive class probabilities untuk setiap observasi feature set valid\n",
    "print('F1 =', f1_score(target_valid, best_rf_pred), 'AUC-ROC =', \\\n",
    "      roc_auc_score(target_valid, probabilities_rf_one_valid))\n",
    "#mencetak nilai f1 score dengan membandingkan predictions dengan target dari set valid sekaligus mencetak nilai auc_roc dengan membandingkan target set valid terhadap positive class probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nilai F1 sebesar 0.59 dengan nilai AUC-ROC sebesar 0.85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression <a name=\"analysis_2_3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selanjutnya kita akan menggunakan fungsi LogisticRegression(). Seperti biasa hyperparamter random_state harus sama, namun untuk hyperparameter max_ depth dan hyperparameter n_estimators tidak diaplikasikan pada model ini. Hyperparameter yang diperlukan adalah solver yang bernilai 'liblinear'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2.9**\n",
    "Menentukan model klasifikasi Logistic Regression dengan nilai F1 tertinggi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 = 0.33108108108108103 AUC-ROC = 0.7587497504824008\n"
     ]
    }
   ],
   "source": [
    "lr_model = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "#membuat model\n",
    "lr_model.fit(features_train, target_train)\n",
    "#train model menggunakan feature dan target dari set train\n",
    "lr_valid_pred=lr_model.predict(features_valid)\n",
    "#mendapatkan prediction dari model menggunakan feature dari set valid\n",
    "probabilities_lr_valid=lr_model.predict_proba(features_valid)\n",
    "#mendapatkan negative class probabilities dan positive class probabilities untuk setiap observasi feature dari set valid\n",
    "probabilities_lr_one_valid=probabilities_lr_valid[:, 1]\n",
    "#mendapatkan positive class probabilities untuk setiap observasi feature set valid\n",
    "print('F1 =', f1_score(target_valid, lr_valid_pred), 'AUC-ROC =', \\\n",
    "     roc_auc_score(target_valid, probabilities_lr_one_valid))\n",
    "#mencetak nilai f1 score dengan membandingkan predictions dengan target dari set valid sekaligus mencetak nilai auc_roc dengan membandingkan target set valid terhadap positive class probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model yang terbaik adalah Random Forest Classifier dengan hyperparameter max_ depth=10 dan hyperparameter n_estimators=10 karena memiliki nilai F1 tertinggi (0,59) dengan nilai AUC-ROC 0,84. Hal ini dapat dijadikan acuan untuk penggunaan ke depannya."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memperhitungkan Class Imbalance <a name=\"analysis_3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us study class imbalance so as to know the portions or shares of each class in the target of the training set. To do so, we will use the value_counts() function and set the parameter normalize=True."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mari kita pelajari Class Imbalance untuk mengetahui porsi atau share masing-masing class dalam target set train. Dalam pelaksanaannya kita akan menggunakan fungsi value_counts() dan mengatur parameter normalize=True."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2.10**\n",
    "Melakukan evaluasi kondisi Class Imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exited\n",
      "0    0.800667\n",
      "1    0.199333\n",
      "Name: proportion, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Exited'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_frequency = target_train.value_counts(normalize=True)\n",
    "print(class_frequency)\n",
    "class_frequency.plot(kind='bar')\n",
    "#melihat unique value dari target_train dan porsi dari keseluruhan data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Porsi negative class (0) sebesar 80% data, sedangkan positive class (1) sebesar 20%. Sehingga dapat dikatakan ada 4 kali lebih banyak angka 0 dibandingkan angka 1. Kita akan menerapkan dua pendekatan untuk mengatasi Class Imbalance ini."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Penyesuaian Class Weight <a name=\"analysis_3_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita perlu melakukan setting hyperparameter class_weight='balanced' saat melatih model. Hal ini akan membuat class yang lebih langka (1 dalam hal ini) memiliki bobot lebih banyak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 = 0.6038647342995168 AUC-ROC = 0.8418065981526625\n"
     ]
    }
   ],
   "source": [
    "bal_rf_model = RandomForestClassifier(random_state=12345, max_depth=10, n_estimators=10, \\\n",
    "                                       class_weight='balanced')\n",
    "#membuat model\n",
    "bal_rf_model.fit(features_train, target_train)\n",
    "#train model menggunakan feature dan target dari set train\n",
    "bal_rf_pred = bal_rf_model.predict(features_valid)\n",
    "#mendapatkan prediction dari model menggunakan feature dari set valid\n",
    "proba_bal_rf_valid=bal_rf_model.predict_proba(features_valid)\n",
    "#mendapatkan negative class probabilities dan positive class probabilities untuk setiap observasi feature dari set valid\n",
    "proba_bal_rf_one_valid=proba_bal_rf_valid[:, 1]\n",
    "#mendapatkan positive class probabilities untuk setiap observasi feature set valid\n",
    "print('F1 =', f1_score(target_valid, bal_rf_pred), 'AUC-ROC =', \\\n",
    "      roc_auc_score(target_valid, proba_bal_rf_one_valid))\n",
    "#mencetak nilai f1 score dengan membandingkan predictions dengan target dari set valid sekaligus mencetak nilai auc_roc dengan membandingkan target set valid terhadap positive class probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nilai F1 sudah lebih baik dari sebelumnya (>0,59), namun untuk nilai AUC-ROC sedikit menurun. True Positive Rate (TPR) juga akan cenderung ikut sedikit menurun."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upsampling <a name=\"analysis_3_2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dalam upsampling, pada dasarnya kita akan mengulang class yang lebih langka dan observasinya dalam waktu yang cukup agar kelas tersebut dapat disandingkan secara merata dengan kelas lainnya. Kita telah melihat sebelumnya bahwa jumlah angka 0 adalah 4 kali lebih banyak daripada jumlah angka 1, sehingga kita akan mengulangi angka 1 dan observasinya sebanyak 4 kali untuk menyandingkannya dengan angka 0 di set train secara merata. Selanjutnya kita harus melakukan pengacakan dengan menggunakan fungsi shuffle()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9588, 11) (9588,)\n"
     ]
    }
   ],
   "source": [
    "def upsample(features, target, repeat):\n",
    "#membuat fungsi upsample dengan argument features, target, dan repeat\n",
    "    features_zeros = features_train[target_train == 0]\n",
    "    #mendapatkan feature berisi negative class\n",
    "    features_ones = features_train[target_train == 1]\n",
    "    #mendapatkan feature berisi positive class\n",
    "    target_zeros = target_train[target_train == 0]\n",
    "    #mendapatkan target berisi negative class\n",
    "    target_ones = target_train[target_train == 1]\n",
    "    #mendapatkan target berisi positive class\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    #melakukan upsampling feature dengan mengkombinasikan feature berisi negative class dan feature berisi positive class yang telah di-repeat\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "    #melakukan upsampling target dengan mengkombinasikan target berisi negative class dan target berisi positive class yang telah di-repeat\n",
    "    features_upsampled, target_upsampled = shuffle(features_upsampled, target_upsampled, random_state=12345)\n",
    "    #mengacak hasil upsampling feature dan target\n",
    "    return features_upsampled, target_upsampled \n",
    "    #mengembalikan nilai hasil upsampling feature dan target\n",
    "\n",
    "features_upsampled, target_upsampled = upsample(features_train, target_train, 4)\n",
    "#melakukan upsamling terhadap set train baik feature maupun target dengan memasukkannya ke dalam fungsi upsample dengan menetapkan konstanta untuk repeat (dalam hal ini 4)\n",
    "print(features_upsampled.shape, target_upsampled.shape)\n",
    "#mencetak ukuran dari set yang sudah dilakukan upsampling baik feature maupun target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sekarang kita dapat melatih model dengan menggunakan feature dan target yang telah ditingkatkan sampelnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 = 0.5836909871244635 AUC-ROC = 0.8335694929197491\n"
     ]
    }
   ],
   "source": [
    "ups_rf_model = RandomForestClassifier(random_state=12345, max_depth=10, n_estimators=10)\n",
    "#membuat model\n",
    "ups_rf_model.fit(features_upsampled, target_upsampled)\n",
    "#train model menggunakan feature dan target dari set train\n",
    "ups_rf_pred = ups_rf_model.predict(features_valid)\n",
    "#mendapatkan prediction dari model menggunakan feature dari set valid\n",
    "proba_ups_rf_valid=ups_rf_model.predict_proba(features_valid)\n",
    "#mendapatkan negative class probabilities dan positive class probabilities untuk setiap observasi feature dari set valid\n",
    "proba_ups_rf_one_valid=proba_ups_rf_valid[:, 1]\n",
    "#mendapatkan positive class probabilities untuk setiap observasi feature set valid\n",
    "print('F1 =', f1_score(target_valid, ups_rf_pred), 'AUC-ROC =', \\\n",
    "      roc_auc_score(target_valid, proba_ups_rf_one_valid))\n",
    "#mencetak nilai f1 score dengan membandingkan predictions dengan target dari set valid sekaligus mencetak nilai auc_roc dengan membandingkan target set valid terhadap positive class probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nilai F1 lebih rendah dari yang telah didapatkan saat menggunakan penyesuaian class weight. Namun, kebalikannya terjadi pada AUC-ROC. True Positive Rate memiliki kecenderungan meningkat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kesimpulan <a name=\"analysis_conclusion\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dengan demikian, kita dapat melanjutkan dengan pendekatan penyesuaian class weight karena memiliki skor F1 yang lebih tinggi yaitu 0,59."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Kembali ke Daftar Isi](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tahap 4. Pengujian <a name='test'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pengujian pada set test <a name=\"test_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model kita (dengan penyesuaian bobot kelas) sudah bisa diterapkan ke set test. Sebelumnya kita perlu melatih model menggunakan set train dan set valid. Untuk keperluan tersebut kita dapat menggunakan fungsi pd.concat()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 = 0.6187214611872146 AUC-ROC = 0.8509656393397403\n"
     ]
    }
   ],
   "source": [
    "features_train_final=pd.concat([features_train] + [features_valid])\n",
    "#membuat tumpukan vertikal dari feature pada set train dan feature pada set valid \n",
    "target_train_final=pd.concat([target_train] + [target_valid])\n",
    "#membuat tumpukan vertikal dari target pada set train dan target pada set valid \n",
    "final_rf_model = RandomForestClassifier(random_state=12345, max_depth=10, n_estimators=10, \\\n",
    "                                       class_weight='balanced')\n",
    "#membuat model\n",
    "final_rf_model.fit(features_train_final, target_train_final)\n",
    "#train model menggunakan feature dan target dari set train\n",
    "final_rf_pred = final_rf_model.predict(features_test)\n",
    "#mendapatkan prediction dari model menggunakan feature dari set valid\n",
    "proba_rf_test=final_rf_model.predict_proba(features_test)\n",
    "#mendapatkan negative class probabilities dan positive class probabilities untuk setiap observasi feature dari set valid\n",
    "proba_rf_one_test=proba_rf_test[:, 1]\n",
    "#mendapatkan positive class probabilities untuk setiap observasi feature set valid\n",
    "print('F1 =', f1_score(target_test, final_rf_pred), 'AUC-ROC =', \\\n",
    "      roc_auc_score(target_test, proba_rf_one_test))\n",
    "#mencetak nilai f1 score dengan membandingkan predictions dengan target dari set valid sekaligus mencetak nilai auc_roc dengan membandingkan target set valid terhadap positive class probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nilai akhir F1 adalah sebesar 0,60 di mana telah melebih ambang batas sebesar 0,59"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temuan <a name=\"end\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita telah melakukan pemrosesan kumpulan data (membuat dummies dari kolom kategorikal, menskalakan kolom numerikal, dan mengisi missing value). \n",
    "Kita telah melakukan split data (tanpa memperhitungkan class imbalance), kita telah melatih model klasifikasi Decision Tree, Random Forest, dan Logistic Regression dan menentukan Random Forest sebagai model klasifikasi yang terbaik dengan nilai f1 tertinggi (0,59) dan nilai ROC-AUC sebesar 0,85.\n",
    "Kemudian dengan memperhitungkan class imbalance, kita menggunakan pendekatan penyesuaian class weight dan upsampling. Dari penggunaan kedua pendekatan tersebut, kita memilih untuk menggunakan penyesuaian class weight karena memiliki nilai F1 lebih tinggi yaitu 0,59 meski upsampling memiliki nilai AUC-ROC lebih tinggi. Pada akhirnya kita melakukan train model dengan set train dan set valid dan menerapkannya pada set test dan mendapatkan nilai F1 sebesar 0,60."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Kembali ke Daftar Isi](#back)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
